{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "34aa937b-faaf-48b2-a2d9-581ec9910025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6a9e9951-676e-43f7-878c-d82f651ecefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mayo = pd.read_csv('/scratch/mcesped/Datasets/segments_mayo.csv', sep=\",\", index_col=\"index\")\n",
    "df_fnusa = pd.read_csv('/scratch/mcesped/Datasets/segments_fnusa.csv', sep=\",\", index_col=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fa656782-ebe9-44a3-a3f5-aa30607f0778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "{0: [7132, 0, 0, 0], 1: [0, 0, 1912, 0], 2: [4315, 2892, 1657, 7809], 3: [0, 12, 8076, 0], 4: [0, 8463, 0, 0], 5: [0, 5059, 1527, 5452], 6: [0, 0, 1554, 962], 7: [2042, 5416, 7738, 2689], 8: [0, 18, 1896, 20860], 9: [0, 0, 6750, 0], 10: [0, 5876, 4260, 1545], 11: [0, 3339, 4072, 2890], 12: [0, 1343, 7710, 38217], 13: [0, 181, 5318, 14136]}\n"
     ]
    }
   ],
   "source": [
    "counter = {\n",
    "    # 'pw':[],\n",
    "    # 'noise':[],\n",
    "    # 'path':[],\n",
    "    # 'phys':[]\n",
    "}\n",
    "df_total = df_fnusa\n",
    "for inst in np.unique(df_total.institution):\n",
    "    df_inst = df_total.loc[df_total.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        counter[subj] = []\n",
    "        for cat_id, cat_name in [(0,'pw'), (1, 'noise'), (2, 'path'), (3,'phys')]:\n",
    "            counter[subj].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dabcf298-562d-4d43-ad90-8836edc985d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.309810582131131"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.sum(counter[7])+np.sum(counter[10]))*100/len(df_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce23098-edfe-47ec-9433-5e4e289b94cf",
   "metadata": {},
   "source": [
    "Only choosing two subjects for validation: **number 7 and number 10 from fnusa** as it is balanced between classes. Representing ~15% of the total fnusa data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52820d-2260-4a36-9e29-9daaa8171d8d",
   "metadata": {},
   "source": [
    "# Noise detection dataset\n",
    "I'll balance the classes manually to have a similar amount of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1ff9722a-eb7d-49e6-a3e2-ba2608dc6013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anatomy</th>\n",
       "      <th>category_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>electrode_type</th>\n",
       "      <th>institution</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>soz</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007132</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7133</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007133</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7134</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007134</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7135</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007135</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007136</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    anatomy  category_id channel electrode_type institution  \\\n",
       "index                                                                         \n",
       "7132   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7133   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7134   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7135   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7136   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "\n",
       "       patient_id  reviewer_id segment_id  soz category_name  \n",
       "index                                                         \n",
       "7132            1            2    y007132    1     pathology  \n",
       "7133            1            2    y007133    1     pathology  \n",
       "7134            1            2    y007134    1     pathology  \n",
       "7135            1            2    y007135    1     pathology  \n",
       "7136            1            2    y007136    1     pathology  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fnusa_no_pw = df_fnusa.loc[df_fnusa.category_id != 0]\n",
    "df_fnusa_no_pw.loc[:,'category_id'] = df_fnusa_no_pw.category_id - 1\n",
    "\n",
    "df_mayo_no_pw = df_mayo.loc[df_mayo.category_id != 0]\n",
    "df_mayo_no_pw.loc[:,'category_id'] = df_mayo_no_pw.category_id - 1\n",
    "\n",
    "df_fnusa_no_pw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89f5f0c-bbd5-4599-b3c5-72072e63d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_mayo_no_pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc04b8e9-dd86-4af0-b600-5dd1572cdf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 10])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df_fnusa_no_pw.loc[(df_fnusa_no_pw.patient_id == 7).astype(bool) | (df_fnusa_no_pw.patient_id == 10).astype(bool) ]\n",
    "df_val.patient_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "155b6f36-ac95-4481-9270-ee2af33a0941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  8,  9, 11, 12, 13])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_fnusa_no_pw.loc[(df_fnusa_no_pw.patient_id != 7).astype(bool) & (df_fnusa_no_pw.patient_id != 10).astype(bool) ]\n",
    "df_test.patient_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b49e70fc-3f04-4e74-a824-f62601cefae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 14, 16, 17, 18, 19, 20, 21,\n",
       "        23]),\n",
       " array([ 7, 10]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  8,  9, 11, 12, 13]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train.patient_id), np.unique(df_val.patient_id), np.unique(df_test.patient_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514e1e5-0ab2-46bd-87ca-36279d806a2b",
   "metadata": {},
   "source": [
    "## Balance datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e298def-cbc3-4a28-8fa3-1ba05caa62fe",
   "metadata": {},
   "source": [
    "Not touching test set as I'll probably do bootstrapping for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "41a5550c-00aa-4953-826e-8948a5e69e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n",
      "{'noise': [1100, 0, 466, 1100, 1100, 1002, 1100, 0, 0, 740, 0, 1100, 1100, 1100, 1100, 1100, 58, 761], 'path': [0, 883, 1500, 0, 0, 0, 0, 0, 1500, 0, 1500, 0, 0, 0, 0, 0, 1500, 1500], 'phys': [330, 1200, 399, 1200, 790, 1200, 0, 1200, 0, 0, 498, 177, 1200, 1200, 0, 1200, 0, 644]}\n",
      "\n",
      " noise \n",
      "Number of subj: 14 \n",
      "Median events per subj 1100.0 \n",
      "Total events proportion 39.71672606611774 \n",
      "Total events: 12927\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 6 \n",
      "Median events per subj 1500.0 \n",
      "Total events proportion 25.755806808406046 \n",
      "Total events: 8383\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 13 \n",
      "Median events per subj 1200.0 \n",
      "Total events proportion 34.52746712547622 \n",
      "Total events: 11238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_train\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "63e95a54-2dc3-4738-8d73-96bbc52a568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n"
     ]
    }
   ],
   "source": [
    "# Manually picked choice\n",
    "# For training: 1500, 2000, 1200. \n",
    "# For val 4000, 2000, 2000\n",
    "max_img_subj_cat = {\n",
    "    'noise': 1000, # Pay more the noise\n",
    "    'path': 750, # Less path at it is not so hard to identify\n",
    "    'phys': 500\n",
    "}\n",
    "df_curated = []\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            df_cat = df_subj.loc[df_subj.category_id==cat_id]\n",
    "            if len(df_curated)<1:\n",
    "                df_curated = df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))\n",
    "            else:\n",
    "                df_curated = pd.concat([df_curated, df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))])\n",
    "df_curated = df_curated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "df809c4f-4260-409c-9638-ef1bf5c659d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n",
      "{'noise': [1000, 0, 466, 1000, 1000, 1000, 1000, 0, 0, 740, 0, 1000, 1000, 1000, 1000, 1000, 58, 761], 'path': [0, 500, 500, 0, 0, 0, 0, 0, 500, 0, 500, 0, 0, 0, 0, 0, 500, 500], 'phys': [330, 500, 399, 500, 500, 500, 0, 500, 0, 0, 498, 177, 500, 500, 0, 500, 0, 500]}\n",
      "\n",
      " noise \n",
      "Number of subj: 14 \n",
      "Median events per subj 1000.0 \n",
      "Total events proportion 57.456161307276986 \n",
      "Total events: 12025\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 6 \n",
      "Median events per subj 500.0 \n",
      "Total events proportion 14.334177457116919 \n",
      "Total events: 3000\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 13 \n",
      "Median events per subj 500.0 \n",
      "Total events proportion 28.209661235606095 \n",
      "Total events: 5904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_curated\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1bdb1a88-b882-4d73-9193-70b0fa1c8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0997b473-86a4-44e7-9dc5-db5749318689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 14, 16, 17, 18, 19, 20, 21,\n",
       "        23]),\n",
       " array([ 7, 10]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  8,  9, 11, 12, 13]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train.patient_id), np.unique(df_val.patient_id), np.unique(df_test.patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20d63983-c664-43b6-b988-072a7b9db750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write csv files\n",
    "df_train.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_train.csv', sep=\",\", index_label='index')\n",
    "df_val.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_val.csv', sep=\",\", index_label='index')\n",
    "df_test.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_test.csv', sep=\",\", index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c1aa3-4749-4742-bb89-865bd7aa8854",
   "metadata": {},
   "source": [
    "# Multiclass (3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0faa25a0-b849-49af-a5e1-b9d82459fb58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anatomy</th>\n",
       "      <th>category_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>electrode_type</th>\n",
       "      <th>institution</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>soz</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007132</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7133</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007133</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7134</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007134</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7135</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007135</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007136</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    anatomy  category_id channel electrode_type institution  \\\n",
       "index                                                                         \n",
       "7132   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7133   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7134   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7135   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7136   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "\n",
       "       patient_id  reviewer_id segment_id  soz category_name  \n",
       "index                                                         \n",
       "7132            1            2    y007132    1     pathology  \n",
       "7133            1            2    y007133    1     pathology  \n",
       "7134            1            2    y007134    1     pathology  \n",
       "7135            1            2    y007135    1     pathology  \n",
       "7136            1            2    y007136    1     pathology  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fnusa_no_pw = df_fnusa.loc[df_fnusa.category_id != 0]\n",
    "df_fnusa_no_pw.loc[:,'category_id'] = df_fnusa_no_pw.category_id - 1\n",
    "\n",
    "df_mayo_no_pw = df_mayo.loc[df_mayo.category_id != 0]\n",
    "df_mayo_no_pw.loc[:,'category_id'] = df_mayo_no_pw.category_id - 1\n",
    "\n",
    "df_fnusa_no_pw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35d9ab78-ac2e-45ce-a036-453f4a5b30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_mayo_no_pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d702e9c2-6294-4249-8b1c-3c2e844f6d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 10])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df_fnusa_no_pw.loc[(df_fnusa_no_pw.patient_id == 7).astype(bool) | (df_fnusa_no_pw.patient_id == 10).astype(bool) ]\n",
    "df_val.patient_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c748efda-2596-47cb-9d52-1882959bcf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  8,  9, 11, 12, 13])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_fnusa_no_pw.loc[(df_fnusa_no_pw.patient_id != 7).astype(bool) & (df_fnusa_no_pw.patient_id != 10).astype(bool) ]\n",
    "df_test.patient_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9d002b1-5044-4837-8c3f-d25c5ddb9ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 14, 16, 17, 18, 19, 20, 21,\n",
       "        23]),\n",
       " array([ 7, 10]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  8,  9, 11, 12, 13]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train.patient_id), np.unique(df_val.patient_id), np.unique(df_test.patient_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c16fe-b7a9-4ee9-b7d4-7112dff027f9",
   "metadata": {},
   "source": [
    "## Balance datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3cb1c2a2-335b-4c9e-b3a7-90e2cdc6d45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "{'noise': [5416, 5876], 'path': [7738, 4260], 'phys': [2689, 1545]}\n",
      "\n",
      " noise \n",
      "Number of subj: 2 \n",
      "Median events per subj 5646.0 \n",
      "Total events proportion 41.02601366080511 \n",
      "Total events: 11292\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 2 \n",
      "Median events per subj 5999.0 \n",
      "Total events proportion 43.591047812817905 \n",
      "Total events: 11998\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 2 \n",
      "Median events per subj 2117.0 \n",
      "Total events proportion 15.38293852637698 \n",
      "Total events: 4234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_val\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b42e12e1-81cc-4046-91e8-a72dd230b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n"
     ]
    }
   ],
   "source": [
    "# Manually picked choice\n",
    "# For training: 1100, 1500, 1200. Chosen to balance it the best I could without giving so much segments\n",
    "# to one class (path) coming from few subjects. Path then has less percentage.\n",
    "# For val 2000 each and phys 2200 (as 1 subject has less data than 2000)\n",
    "max_img_subj_cat = {\n",
    "    'noise': 2000, # Pay more the noise\n",
    "    'path': 2000, # Less path at it is not so hard to identify\n",
    "    'phys': 2200\n",
    "}\n",
    "df_curated = []\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            df_cat = df_subj.loc[df_subj.category_id==cat_id]\n",
    "            if len(df_curated)<1:\n",
    "                df_curated = df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))\n",
    "            else:\n",
    "                df_curated = pd.concat([df_curated, df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))])\n",
    "df_curated = df_curated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e84a1678-ce91-48ba-86b6-d519dadcbf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "{'noise': [2000, 2000], 'path': [2000, 2000], 'phys': [2200, 1545]}\n",
      "\n",
      " noise \n",
      "Number of subj: 2 \n",
      "Median events per subj 2000.0 \n",
      "Total events proportion 34.05704555129842 \n",
      "Total events: 4000\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 2 \n",
      "Median events per subj 2000.0 \n",
      "Total events proportion 34.05704555129842 \n",
      "Total events: 4000\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 2 \n",
      "Median events per subj 1872.5 \n",
      "Total events proportion 31.88590889740315 \n",
      "Total events: 3745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_curated\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d6f40a93-bc0a-4ec5-b5eb-68988ed3bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "406ae96f-9034-4a02-ab5a-96f6c2f79c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 14, 16, 17, 18, 19, 20, 21,\n",
       "        23]),\n",
       " array([ 7, 10]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  8,  9, 11, 12, 13]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train.patient_id), np.unique(df_val.patient_id), np.unique(df_test.patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f16b1f8-1011-4583-8907-4cef4925d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write csv files\n",
    "df_train.to_csv('/scratch/mcesped/Datasets/Multiclass/df_train.csv', sep=\",\", index_label='index')\n",
    "df_val.to_csv('/scratch/mcesped/Datasets/Multiclass/df_val.csv', sep=\",\", index_label='index')\n",
    "df_test.to_csv('/scratch/mcesped/Datasets/Multiclass/df_test.csv', sep=\",\", index_label='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
