{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb1fb29-b163-427a-bc17-12bc94fb1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ffcd63-3d82-462e-bdcc-db24a3a3787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AutoFeatureExtractor.pk', 'rb') as f:\n",
    "    feature_extractor = pickle.load(f)\n",
    "with open('model.pk', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017672c2-156d-45bc-a131-bb488ed8c9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"ASTFeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"max_length\": 1024,\n",
       "  \"mean\": -4.2677393,\n",
       "  \"num_mel_bins\": 128,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": false,\n",
       "  \"sampling_rate\": 16000,\n",
       "  \"std\": 4.5689974\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faeaf0f9-943d-42c6-8dd0-a0c77f89b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "import zipfile\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "sys.path.insert(0,'/scratch/mcesped/code/NoiseDetection_iEEG/interictal_classifier/')\n",
    "import features\n",
    "from scipy import stats\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42831876-49b0-4cbb-b986-14feb7cd5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load zip files\n",
    "# zip_map = {\n",
    "#     'fnusa': '/home/mcesped/scratch/Datasets/Dataset_Fnusa_1024.zip', \n",
    "#     'mayo': '/home/mcesped/scratch/Datasets/Dataset_Mayo_1024.zip',\n",
    "#     'UFlorida': '/home/mcesped/scratch/Datasets/Dataset_UFlorida_1024.zip'\n",
    "# }\n",
    "srate=1024\n",
    "zip_map = {\n",
    "    'fnusa': f'/home/mcesped/scratch/Datasets/Dataset_Fnusa_{srate}.zip', \n",
    "    'mayo': f'/home/mcesped/scratch/Datasets/Dataset_Mayo_{srate}.zip',\n",
    "    'UFlorida': f'/home/mcesped/scratch/Datasets/Dataset_UFlorida_{srate}.zip'\n",
    "}\n",
    "filename_map = {\n",
    "    'fnusa': 'Dataset_Fnusa/', \n",
    "    'mayo': 'Dataset_Mayo/',\n",
    "    'UFlorida': 'Dataset_UFlorida/'\n",
    "}\n",
    "\n",
    "df_mayo = pd.read_csv('/scratch/mcesped/Datasets/segments_mayo.csv', sep=\",\", index_col=\"index\")\n",
    "# df_florida = pd.read_csv('/scratch/mcesped/Datasets/segments_uflorida.csv', sep=\",\", index_col=\"index\")\n",
    "# df_fnusa = pd.read_csv('/scratch/mcesped/Datasets/segments_fnusa.csv', sep=\",\", index_col=\"index\")\n",
    "df_total = df_mayo#pd.concat([df_mayo, df_fnusa])\n",
    "\n",
    "data = {\n",
    "    'pw': [],\n",
    "    'noise': [],\n",
    "    'pathology': [],\n",
    "    'physiology': []\n",
    "}\n",
    "\n",
    "id_to_name={\n",
    "    0: 'pw',\n",
    "    1: 'noise',\n",
    "    2: 'pathology',\n",
    "    3: 'physiology'\n",
    "}\n",
    "\n",
    "df_got = pd.DataFrame(columns=df_total.columns)\n",
    "\n",
    "for cat_id in (1,2,3):\n",
    "    # Get df with category \n",
    "    df_tmp = df_total.loc[df_total.category_id == cat_id]\n",
    "    # Random sample\n",
    "    df_random = df_tmp.sample(n=2).reset_index(drop=True)\n",
    "    df_got = pd.concat([df_got, df_random])\n",
    "    # Get cat name\n",
    "    cat_name = id_to_name[cat_id]\n",
    "    for id in df_random.index:\n",
    "        # Get inst and id \n",
    "        inst = df_random.loc[id,'institution']\n",
    "        seg_id  = df_random.loc[id,'segment_id']\n",
    "        file_name = os.path.join(filename_map[inst], seg_id+'.npy')\n",
    "        zip_file = zip_map[inst]\n",
    "        with zipfile.ZipFile(zip_file, mode=\"r\") as f:\n",
    "            # Get all files\n",
    "            files = f.namelist()\n",
    "            # print(len(files))\n",
    "            # print(file_name)\n",
    "            # Open 1 files to check\n",
    "            with f.open(file_name) as myfile:\n",
    "                # data = pd.read_csv(myfile, sep=\",\", index_col=\"Unnamed: 0\")\n",
    "                # print(data.head())\n",
    "                data_tmp = np.load(myfile)\n",
    "                # print(data.shape)\n",
    "            # Append to data\n",
    "            data[cat_name].append(data_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260fe261-53b0-4da9-9d5b-4b982f50f027",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model corresponding to this feature extractor: ASTFeatureExtractor {\n  \"do_normalize\": true,\n  \"feature_extractor_type\": \"ASTFeatureExtractor\",\n  \"feature_size\": 1,\n  \"max_length\": 1024,\n  \"mean\": -4.2677393,\n  \"num_mel_bins\": 128,\n  \"padding_side\": \"right\",\n  \"padding_value\": 0.0,\n  \"return_attention_mask\": false,\n  \"sampling_rate\": 16000,\n  \"std\": 4.5689974\n}\n was trained using a sampling rate of 16000. Please make sure that the provided `raw_speech` input was sampled with 16000 and not 1024.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnoise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m inputs\n",
      "File \u001b[0;32m/local/mcesped.18230375.0/tmp/kslurm-venv-zk63iuq8/lib/python3.10/site-packages/transformers/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.py:189\u001b[0m, in \u001b[0;36mASTFeatureExtractor.__call__\u001b[0;34m(self, raw_speech, sampling_rate, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampling_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampling_rate \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate:\n\u001b[0;32m--> 189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    190\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model corresponding to this feature extractor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was trained using a sampling rate of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure that the provided `raw_speech` input was sampled with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m         )\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is strongly recommended to pass the `sampling_rate` argument to this function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailing to do so can result in silent errors that might be hard to debug.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The model corresponding to this feature extractor: ASTFeatureExtractor {\n  \"do_normalize\": true,\n  \"feature_extractor_type\": \"ASTFeatureExtractor\",\n  \"feature_size\": 1,\n  \"max_length\": 1024,\n  \"mean\": -4.2677393,\n  \"num_mel_bins\": 128,\n  \"padding_side\": \"right\",\n  \"padding_value\": 0.0,\n  \"return_attention_mask\": false,\n  \"sampling_rate\": 16000,\n  \"std\": 4.5689974\n}\n was trained using a sampling rate of 16000. Please make sure that the provided `raw_speech` input was sampled with 16000 and not 1024."
     ]
    }
   ],
   "source": [
    "inputs = feature_extractor(data['noise'][0], sampling_rate=1024, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81443bfe-9224-4b22-9bb2-b1a1af94d063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29242923, 0.44591592, 0.22355713, ..., 0.8106826 , 0.74143929,\n",
       "       0.80599804])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['noise'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
