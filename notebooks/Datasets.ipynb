{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34aa937b-faaf-48b2-a2d9-581ec9910025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9e9951-676e-43f7-878c-d82f651ecefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mayo = pd.read_csv('/scratch/mcesped/Datasets/segments_mayo.csv', sep=\",\", index_col=\"index\")\n",
    "df_fnusa = pd.read_csv('/scratch/mcesped/Datasets/segments_fnusa.csv', sep=\",\", index_col=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bad19a-d6c2-418b-a2b6-0b083758c8d1",
   "metadata": {},
   "source": [
    "# Noise detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b954728-bbf9-46d6-ba95-ffd0bfcf89e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fnusa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2dca0-70ed-4bc4-9519-c8952c7f053a",
   "metadata": {},
   "source": [
    "I'll use fnusa for training as it has more data after curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa656782-ebe9-44a3-a3f5-aa30607f0778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "{'noise': [0, 2892, 12, 8463, 5059, 0, 5416, 18, 0, 5876, 3339, 1343, 181], 'path': [1912, 1657, 8076, 0, 1527, 1554, 7738, 1896, 6750, 4260, 4072, 7710, 5318], 'phys': [0, 7809, 0, 0, 5452, 962, 2689, 20860, 0, 1545, 2890, 38217, 14136]}\n"
     ]
    }
   ],
   "source": [
    "counter = {\n",
    "    # 'pw':[],\n",
    "    # 'noise':[],\n",
    "    # 'path':[],\n",
    "    # 'phys':[]\n",
    "}\n",
    "df_evaluated = df_fnusa\n",
    "# Remove power line\n",
    "df_evaluated = df_evaluated.loc[df_evaluated.category_id != 0]\n",
    "df_evaluated.loc[:,'category_id'] = df_evaluated.category_id - 1\n",
    "\n",
    "counter = {\n",
    "    # 'pw':[],\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1d0de8-df32-4e62-8eb1-0ba5eb6e88cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise \n",
      "Number of subj: 10 \n",
      "Median events per subj 3115.5 \n",
      "Total events proportion 18.147960518624497 \n",
      "Total events: 32599\n",
      "\n",
      "path \n",
      "Number of subj: 12 \n",
      "Median events per subj 4166.0 \n",
      "Total events proportion 29.21020547907075 \n",
      "Total events: 52470\n",
      "\n",
      "phys \n",
      "Number of subj: 9 \n",
      "Median events per subj 5452.0 \n",
      "Total events proportion 52.64183400230475 \n",
      "Total events: 94560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print(cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d53267d-f5b3-4061-bd16-b09724956bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n"
     ]
    }
   ],
   "source": [
    "# Curate\n",
    "max_img_subj_cat = {\n",
    "    'noise': 3000, # Pay more the noise\n",
    "    'path': 800, # Less path at it is not so hard to identify\n",
    "    'phys': 1300\n",
    "}\n",
    "df_curated = []\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            df_cat = df_subj.loc[df_subj.category_id==cat_id]\n",
    "            if len(df_curated)<1:\n",
    "                df_curated = df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))\n",
    "            else:\n",
    "                df_curated = pd.concat([df_curated, df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))])\n",
    "df_curated = df_curated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4db118-5484-4bbe-8dea-3a04b84a47bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40408"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_curated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8459bb9-a424-488f-9e54-96f030876d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "noise \n",
      "Number of subj: 10 \n",
      "Median events per subj 2946.0 \n",
      "Total events proportion 48.124133834884184 \n",
      "Total events: 19446\n",
      "\n",
      "path \n",
      "Number of subj: 12 \n",
      "Median events per subj 800.0 \n",
      "Total events proportion 23.75767174816868 \n",
      "Total events: 9600\n",
      "\n",
      "phys \n",
      "Number of subj: 9 \n",
      "Median events per subj 1300.0 \n",
      "Total events proportion 28.11819441694714 \n",
      "Total events: 11362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_curated\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print(cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086f64a-70e4-4369-ae3a-bca2549f1d1c",
   "metadata": {},
   "source": [
    "Therefore, for a 70/30 split, we would need in the val set per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318beac1-4945-4e08-911f-ce09f207aee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise \n",
      "Total events in val set: 5833.8\n",
      "\n",
      "path \n",
      "Total events in val set: 2880.0\n",
      "\n",
      "phys \n",
      "Total events in val set: 3408.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print(cat, f'\\nTotal events in val set: {np.sum(array_count)*0.3}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04aad005-1b29-4c01-b2e7-d78f8e25fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48124133834884186, 0.2375767174816868, 0.2811819441694714)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This would mean a dist of:\n",
    "total = 5833.8+2880.0+3408.6\n",
    "5833.8/total, 2880.0/total, 3408.6/total\n",
    "# This is great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c3ee06-6723-49f5-b4f5-0890df03b9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 800, 0)\n",
      "(2892, 800, 1300)\n",
      "(12, 800, 0)\n",
      "(3000, 0, 0)\n",
      "(3000, 800, 1300)\n",
      "(0, 800, 962)\n",
      "(3000, 800, 1300)\n",
      "(18, 800, 1300)\n",
      "(0, 800, 0)\n",
      "(3000, 800, 1300)\n",
      "(3000, 800, 1300)\n",
      "(1343, 800, 1300)\n",
      "(181, 800, 1300)\n"
     ]
    }
   ],
   "source": [
    "for tuple_events in zip(counter['noise'],counter['path'],counter['phys']):\n",
    "    print(tuple_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d69e243-e11f-49d8-8331-ac077ca7b9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_curated.patient_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e6bd3-5f7c-4c78-84fa-30e678e32b8c",
   "metadata": {},
   "source": [
    "Based on this distribution:\n",
    "**Val subjects:** 2, 7, 6, 9\n",
    "\n",
    "- Noise: 2892, 3000, 0\n",
    "- Path: 800, 800,800\n",
    "- Phys: 1300, 1300, 962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ed6121-7982-4684-a40e-23e31c106af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-58, -320.0, -153)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5834-2892-3000, 2880.0-800-800-800-800, 3409-1300-1300-962"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c335207-6efd-4708-8440-f6ad1fa56b8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Mayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aff16972-40f4-425f-9f16-e0c74b62ae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n",
      "{'noise': [2318, 0, 466, 4636, 2063, 1002, 12873, 0, 0, 740, 0, 3699, 4096, 1700, 5613, 1278, 58, 761], 'path': [0, 883, 1923, 0, 0, 0, 0, 0, 2816, 0, 3426, 0, 0, 0, 0, 0, 3432, 2747], 'phys': [330, 8653, 399, 2057, 790, 6583, 0, 25951, 0, 0, 498, 177, 6098, 3126, 0, 1424, 0, 644]}\n"
     ]
    }
   ],
   "source": [
    "counter = {\n",
    "    # 'pw':[],\n",
    "    # 'noise':[],\n",
    "    # 'path':[],\n",
    "    # 'phys':[]\n",
    "}\n",
    "df_evaluated = df_mayo\n",
    "# Remove power line\n",
    "df_evaluated = df_evaluated.loc[df_evaluated.category_id != 0]\n",
    "df_evaluated.loc[:,'category_id'] = df_evaluated.category_id - 1\n",
    "\n",
    "counter = {\n",
    "    # 'pw':[],\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7fb7dd2-d29f-4a7a-a31b-41bb265c9410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise \n",
      "Number of subj: 14 \n",
      "Median events per subj 1881.5 \n",
      "Total events proportion 36.46742009535582 \n",
      "Total events: 41303\n",
      "\n",
      "path \n",
      "Number of subj: 6 \n",
      "Median events per subj 2781.5 \n",
      "Total events proportion 13.444287480134204 \n",
      "Total events: 15227\n",
      "\n",
      "phys \n",
      "Number of subj: 13 \n",
      "Median events per subj 1424.0 \n",
      "Total events proportion 50.08829242450998 \n",
      "Total events: 56730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print(cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d904fc87-574f-468e-a4c5-98cada034cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n"
     ]
    }
   ],
   "source": [
    "# Curate\n",
    "max_img_subj_cat = {\n",
    "    'noise': 1800, # Pay more the noise\n",
    "    'path': 1000, # Less path at it is not so hard to identify\n",
    "    'phys': 1000\n",
    "}\n",
    "df_curated = []\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            df_cat = df_subj.loc[df_subj.category_id==cat_id]\n",
    "            if len(df_curated)<1:\n",
    "                df_curated = df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))\n",
    "            else:\n",
    "                df_curated = pd.concat([df_curated, df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))])\n",
    "df_curated = df_curated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c86d85d-58f0-4133-a080-a036e02eb590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34326"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_curated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f269ec2b-7512-4c34-a00c-049fb39f737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n",
      "noise \n",
      "Number of subj: 14 \n",
      "Median events per subj 1750.0 \n",
      "Total events proportion 54.20089727903047 \n",
      "Total events: 18605\n",
      "\n",
      "path \n",
      "Number of subj: 6 \n",
      "Median events per subj 1000.0 \n",
      "Total events proportion 17.138612130746374 \n",
      "Total events: 5883\n",
      "\n",
      "phys \n",
      "Number of subj: 13 \n",
      "Median events per subj 1000.0 \n",
      "Total events proportion 28.660490590223155 \n",
      "Total events: 9838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_curated\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print(cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce23098-edfe-47ec-9433-5e4e289b94cf",
   "metadata": {},
   "source": [
    "Only choosing two subjects for validation: **number 7 and number 10 from fnusa** as it is balanced between classes. Representing ~15% of the total fnusa data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52820d-2260-4a36-9e29-9daaa8171d8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Noise detection dataset\n",
    "I'll balance the classes manually to have a similar amount of training examples per subject. The biggest will be training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff9722a-eb7d-49e6-a3e2-ba2608dc6013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anatomy</th>\n",
       "      <th>category_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>electrode_type</th>\n",
       "      <th>institution</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>soz</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007132</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7133</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007133</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7134</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007134</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7135</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007135</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007136</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    anatomy  category_id channel electrode_type institution  \\\n",
       "index                                                                         \n",
       "7132   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7133   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7134   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7135   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7136   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "\n",
       "       patient_id  reviewer_id segment_id  soz category_name  \n",
       "index                                                         \n",
       "7132            1            2    y007132    1     pathology  \n",
       "7133            1            2    y007133    1     pathology  \n",
       "7134            1            2    y007134    1     pathology  \n",
       "7135            1            2    y007135    1     pathology  \n",
       "7136            1            2    y007136    1     pathology  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fnusa_no_pw = df_fnusa.loc[df_fnusa.category_id != 0]\n",
    "df_fnusa_no_pw.loc[:,'category_id'] = df_fnusa_no_pw.category_id - 1\n",
    "\n",
    "df_mayo_no_pw = df_mayo.loc[df_mayo.category_id != 0]\n",
    "df_mayo_no_pw.loc[:,'category_id'] = df_mayo_no_pw.category_id - 1\n",
    "\n",
    "df_fnusa_no_pw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514e1e5-0ab2-46bd-87ca-36279d806a2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Balance Fnusa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e298def-cbc3-4a28-8fa3-1ba05caa62fe",
   "metadata": {},
   "source": [
    "Not touching test set as I'll probably do bootstrapping for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a5550c-00aa-4953-826e-8948a5e69e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "{'noise': [0, 2892, 12, 8463, 5059, 0, 5416, 18, 0, 5876, 3339, 1343, 181], 'path': [1912, 1657, 8076, 0, 1527, 1554, 7738, 1896, 6750, 4260, 4072, 7710, 5318], 'phys': [0, 7809, 0, 0, 5452, 962, 2689, 20860, 0, 1545, 2890, 38217, 14136]}\n",
      "\n",
      " noise \n",
      "Number of subj: 10 \n",
      "Median events per subj 3115.5 \n",
      "Total events proportion 18.147960518624497 \n",
      "Total events: 32599\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 12 \n",
      "Median events per subj 4166.0 \n",
      "Total events proportion 29.21020547907075 \n",
      "Total events: 52470\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 9 \n",
      "Median events per subj 5452.0 \n",
      "Total events proportion 52.64183400230475 \n",
      "Total events: 94560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_fnusa_no_pw\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e95a54-2dc3-4738-8d73-96bbc52a568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n"
     ]
    }
   ],
   "source": [
    "# Manually picked choice\n",
    "# For training: 1500, 2000, 1200. \n",
    "# For val 4000, 2000, 2000\n",
    "max_img_subj_cat = {\n",
    "    'noise': 3000, # Pay more the noise\n",
    "    'path': 800, # Less path at it is not so hard to identify\n",
    "    'phys': 1500\n",
    "}\n",
    "df_curated = []\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            df_cat = df_subj.loc[df_subj.category_id==cat_id]\n",
    "            if len(df_curated)<1:\n",
    "                df_curated = df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))\n",
    "            else:\n",
    "                df_curated = pd.concat([df_curated, df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))])\n",
    "df_curated = df_curated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df809c4f-4260-409c-9638-ef1bf5c659d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "{'noise': [0, 2892, 12, 3000, 3000, 0, 3000, 18, 0, 3000, 3000, 1343, 181], 'path': [800, 800, 800, 0, 800, 800, 800, 800, 800, 800, 800, 800, 800], 'phys': [0, 1500, 0, 0, 1500, 962, 1500, 1500, 0, 1500, 1500, 1500, 1500]}\n",
      "\n",
      " noise \n",
      "Number of subj: 10 \n",
      "Median events per subj 2946.0 \n",
      "Total events proportion 46.29118263187964 \n",
      "Total events: 19446\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 12 \n",
      "Median events per subj 800.0 \n",
      "Total events proportion 22.852789944772425 \n",
      "Total events: 9600\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 9 \n",
      "Median events per subj 1500.0 \n",
      "Total events proportion 30.856027423347935 \n",
      "Total events: 12962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_curated\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bdb1a88-b882-4d73-9193-70b0fa1c8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curated_fnusa = df_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd489dc4-fdee-4338-b1b6-08baaff56a0a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42008"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_curated_fnusa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c796545f-20c9-45cc-a4fc-f07ed5e8b788",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Balance Mayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ffbc88f-8d7e-430b-8d3c-d5f122105474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n",
      "{'noise': [2318, 0, 466, 4636, 2063, 1002, 12873, 0, 0, 740, 0, 3699, 4096, 1700, 5613, 1278, 58, 761], 'path': [0, 883, 1923, 0, 0, 0, 0, 0, 2816, 0, 3426, 0, 0, 0, 0, 0, 3432, 2747], 'phys': [330, 8653, 399, 2057, 790, 6583, 0, 25951, 0, 0, 498, 177, 6098, 3126, 0, 1424, 0, 644]}\n",
      "\n",
      " noise \n",
      "Number of subj: 14 \n",
      "Median events per subj 1881.5 \n",
      "Total events proportion 36.46742009535582 \n",
      "Total events: 41303\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 6 \n",
      "Median events per subj 2781.5 \n",
      "Total events proportion 13.444287480134204 \n",
      "Total events: 15227\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 13 \n",
      "Median events per subj 1424.0 \n",
      "Total events proportion 50.08829242450998 \n",
      "Total events: 56730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_mayo_no_pw\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91b18e6-c7b9-476b-8570-01f9fb9b8f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n"
     ]
    }
   ],
   "source": [
    "# Manually picked choice\n",
    "# For training: 1500, 2000, 1200. \n",
    "# For val 4000, 2000, 2000\n",
    "max_img_subj_cat = {\n",
    "    'noise': 2000, # Pay more the noise\n",
    "    'path': 1500, # Less path at it is not so hard to identify\n",
    "    'phys': 1300\n",
    "}\n",
    "df_curated = []\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            df_cat = df_subj.loc[df_subj.category_id==cat_id]\n",
    "            if len(df_curated)<1:\n",
    "                df_curated = df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))\n",
    "            else:\n",
    "                df_curated = pd.concat([df_curated, df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))])\n",
    "df_curated = df_curated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0997b473-86a4-44e7-9dc5-db5749318689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n",
      "{'noise': [2000, 0, 466, 2000, 2000, 1002, 2000, 0, 0, 740, 0, 2000, 2000, 1700, 2000, 1278, 58, 761], 'path': [0, 883, 1500, 0, 0, 0, 0, 0, 1500, 0, 1500, 0, 0, 0, 0, 0, 1500, 1500], 'phys': [330, 1300, 399, 1300, 790, 1300, 0, 1300, 0, 0, 498, 177, 1300, 1300, 0, 1300, 0, 644]}\n",
      "\n",
      " noise \n",
      "Number of subj: 14 \n",
      "Median events per subj 1850.0 \n",
      "Total events proportion 49.6081932252145 \n",
      "Total events: 20005\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 6 \n",
      "Median events per subj 1500.0 \n",
      "Total events proportion 20.788077171055896 \n",
      "Total events: 8383\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 13 \n",
      "Median events per subj 1300.0 \n",
      "Total events proportion 29.603729603729604 \n",
      "Total events: 11938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_curated\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e613b51e-eadc-46da-898a-ed11579c8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curated_mayo = df_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f5e924-eb20-4e5a-85d7-a24d14787b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40326, 42008)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_curated_mayo), len(df_curated_fnusa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f8dbb81-00c6-46cd-9805-47ed1e0c4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_curated_fnusa\n",
    "df_val = df_curated_mayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d63983-c664-43b6-b988-072a7b9db750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write csv files. Using fnusa as train\n",
    "df_train.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_train_curated.csv', sep=\",\", index_label='index')\n",
    "df_val.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_val_curated.csv', sep=\",\", index_label='index')\n",
    "# df_test.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_test.csv', sep=\",\", index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "add02aeb-0e8b-4980-8a0f-f57a8ed0e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fnusa_no_pw.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_train_full.csv', sep=\",\", index_label='index')\n",
    "df_mayo_no_pw.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_val_full.csv', sep=\",\", index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c1aa3-4749-4742-bb89-865bd7aa8854",
   "metadata": {},
   "source": [
    "# Multiclass (3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9fc98c-2309-4fef-b04c-d3945d59e443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anatomy</th>\n",
       "      <th>category_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>electrode_type</th>\n",
       "      <th>institution</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>soz</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007132</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7133</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007133</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7134</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007134</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7135</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007135</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>hippocampus anterior</td>\n",
       "      <td>1</td>\n",
       "      <td>B'1</td>\n",
       "      <td>depth</td>\n",
       "      <td>fnusa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>y007136</td>\n",
       "      <td>1</td>\n",
       "      <td>pathology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    anatomy  category_id channel electrode_type institution  \\\n",
       "index                                                                         \n",
       "7132   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7133   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7134   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7135   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "7136   hippocampus anterior            1     B'1          depth       fnusa   \n",
       "\n",
       "       patient_id  reviewer_id segment_id  soz category_name  \n",
       "index                                                         \n",
       "7132            1            2    y007132    1     pathology  \n",
       "7133            1            2    y007133    1     pathology  \n",
       "7134            1            2    y007134    1     pathology  \n",
       "7135            1            2    y007135    1     pathology  \n",
       "7136            1            2    y007136    1     pathology  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fnusa_no_pw = df_fnusa.loc[df_fnusa.category_id != 0]\n",
    "df_fnusa_no_pw.loc[:,'category_id'] = df_fnusa_no_pw.category_id - 1\n",
    "\n",
    "df_mayo_no_pw = df_mayo.loc[df_mayo.category_id != 0]\n",
    "df_mayo_no_pw.loc[:,'category_id'] = df_mayo_no_pw.category_id - 1\n",
    "\n",
    "df_fnusa_no_pw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009259af-2051-4958-a7ad-2899355cffe3",
   "metadata": {},
   "source": [
    "## Balance Fnusa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0135a6-758f-4229-84f2-7f8f9cb74030",
   "metadata": {},
   "source": [
    "Not touching test set as I'll probably do bootstrapping for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850f6ef2-d337-4d5d-a691-12e8e83cd4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "{'noise': [0, 2892, 12, 8463, 5059, 0, 5416, 18, 0, 5876, 3339, 1343, 181], 'path': [1912, 1657, 8076, 0, 1527, 1554, 7738, 1896, 6750, 4260, 4072, 7710, 5318], 'phys': [0, 7809, 0, 0, 5452, 962, 2689, 20860, 0, 1545, 2890, 38217, 14136]}\n",
      "\n",
      " noise \n",
      "Number of subj: 10 \n",
      "Median events per subj 3115.5 \n",
      "Total events proportion 18.147960518624497 \n",
      "Total events: 32599\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 12 \n",
      "Median events per subj 4166.0 \n",
      "Total events proportion 29.21020547907075 \n",
      "Total events: 52470\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 9 \n",
      "Median events per subj 5452.0 \n",
      "Total events proportion 52.64183400230475 \n",
      "Total events: 94560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_fnusa_no_pw\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ca998e-e491-4aef-898f-9eeada6d4e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_img_subj_cat = {\n",
    "    'noise': 3100, # Pay more the noise and physiology\n",
    "    'path': 500, # Less path at it is not so hard to identify. Before in 1000\n",
    "    'phys': 4000\n",
    "}\n",
    "df_curated = []\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            df_cat = df_subj.loc[df_subj.category_id==cat_id]\n",
    "            if len(df_curated)<1:\n",
    "                df_curated = df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))\n",
    "            else:\n",
    "                df_curated = pd.concat([df_curated, df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))])\n",
    "df_curated = df_curated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "568bd82d-ff2a-4aaf-ac49-1d48dc37bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst fnusa\n",
      "{'noise': [0, 2892, 12, 3100, 3100, 0, 3100, 18, 0, 3100, 3100, 1343, 181], 'path': [500, 500, 500, 0, 500, 500, 500, 500, 500, 500, 500, 500, 500], 'phys': [0, 4000, 0, 0, 4000, 962, 2689, 4000, 0, 1545, 2890, 4000, 4000]}\n",
      "\n",
      " noise \n",
      "Number of subj: 10 \n",
      "Median events per subj 2996.0 \n",
      "Total events proportion 36.91516138584542 \n",
      "Total events: 19946\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 12 \n",
      "Median events per subj 500.0 \n",
      "Total events proportion 11.10453064850459 \n",
      "Total events: 6000\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 9 \n",
      "Median events per subj 4000.0 \n",
      "Total events proportion 51.980307965649985 \n",
      "Total events: 28086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_curated\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "343c493c-ffbf-42c9-ae94-b48533a53aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curated_fnusa = df_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc62ba6-127e-4f57-a547-bd4a6a4d6de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54032"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_curated_fnusa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adadcc3-885a-4c63-befd-96ae1931e744",
   "metadata": {},
   "source": [
    "## Balance Mayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665f2f08-17da-418d-bee2-204265046592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n",
      "{'noise': [2318, 0, 466, 4636, 2063, 1002, 12873, 0, 0, 740, 0, 3699, 4096, 1700, 5613, 1278, 58, 761], 'path': [0, 883, 1923, 0, 0, 0, 0, 0, 2816, 0, 3426, 0, 0, 0, 0, 0, 3432, 2747], 'phys': [330, 8653, 399, 2057, 790, 6583, 0, 25951, 0, 0, 498, 177, 6098, 3126, 0, 1424, 0, 644]}\n",
      "\n",
      " noise \n",
      "Number of subj: 14 \n",
      "Median events per subj 1881.5 \n",
      "Total events proportion 36.46742009535582 \n",
      "Total events: 41303\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 6 \n",
      "Median events per subj 2781.5 \n",
      "Total events proportion 13.444287480134204 \n",
      "Total events: 15227\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 13 \n",
      "Median events per subj 1424.0 \n",
      "Total events proportion 50.08829242450998 \n",
      "Total events: 56730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_mayo_no_pw\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daf198b4-9cce-423d-872a-4bd1873ff23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n"
     ]
    }
   ],
   "source": [
    "# Manually picked choice\n",
    "# For training: 1500, 2000, 1200. \n",
    "# For val 4000, 2000, 2000\n",
    "max_img_subj_cat = {\n",
    "    'noise': 1500, # Pay more the noise\n",
    "    'path': 2800, # Less path at it is not so hard to identify\n",
    "    'phys': 2000\n",
    "}\n",
    "df_curated = []\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            df_cat = df_subj.loc[df_subj.category_id==cat_id]\n",
    "            if len(df_curated)<1:\n",
    "                df_curated = df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))\n",
    "            else:\n",
    "                df_curated = pd.concat([df_curated, df_cat.sample(min(len(df_cat),max_img_subj_cat[cat_name]))])\n",
    "df_curated = df_curated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5484b0f8-9022-4d79-ade0-94bf187a4e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects from inst mayo\n",
      "{'noise': [1500, 0, 466, 1500, 1500, 1002, 1500, 0, 0, 740, 0, 1500, 1500, 1500, 1500, 1278, 58, 761], 'path': [0, 883, 1923, 0, 0, 0, 0, 0, 2800, 0, 2800, 0, 0, 0, 0, 0, 2800, 2747], 'phys': [330, 2000, 399, 2000, 790, 2000, 0, 2000, 0, 0, 498, 177, 2000, 2000, 0, 1424, 0, 644]}\n",
      "\n",
      " noise \n",
      "Number of subj: 14 \n",
      "Median events per subj 1500.0 \n",
      "Total events proportion 35.04944110060189 \n",
      "Total events: 16305\n",
      "\n",
      "\n",
      " path \n",
      "Number of subj: 6 \n",
      "Median events per subj 2773.5 \n",
      "Total events proportion 29.993551160791057 \n",
      "Total events: 13953\n",
      "\n",
      "\n",
      " phys \n",
      "Number of subj: 13 \n",
      "Median events per subj 1424.0 \n",
      "Total events proportion 34.957007738607054 \n",
      "Total events: 16262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "counter = {\n",
    "    'noise':[],\n",
    "    'path':[],\n",
    "    'phys':[]\n",
    "}\n",
    "df_evaluated = df_curated\n",
    "for inst in np.unique(df_evaluated.institution):\n",
    "    df_inst = df_evaluated.loc[df_evaluated.institution==inst]\n",
    "    print(f'subjects from inst {inst}')\n",
    "    for subj in np.unique(df_inst.patient_id):\n",
    "        df_subj = df_inst.loc[df_inst.patient_id==subj]\n",
    "        for cat_id, cat_name in [(0, 'noise'), (1, 'path'), (2,'phys')]:\n",
    "            counter[cat_name].append(len(df_subj.loc[df_subj.category_id==cat_id]))\n",
    "print(counter)\n",
    "for cat in counter:\n",
    "    array_count = np.array(counter[cat])\n",
    "    print('\\n',cat,f'\\nNumber of subj: {len(array_count[array_count!=0])}', f'\\nMedian events per subj {np.median(array_count[array_count!=0])}',f'\\nTotal events proportion {np.sum(array_count)*100/len(df_evaluated)}', f'\\nTotal events: {np.sum(array_count)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b33036-5ec0-4af5-a23a-608cc3a33bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curated_mayo = df_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6fa3550-0702-4b84-b9fc-e944e5bb0fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46520, 54032)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_curated_mayo), len(df_curated_fnusa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abb03fd1-45ae-4045-8630-f780168c07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_curated_fnusa\n",
    "df_val = df_curated_mayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf982f1-b88d-47e2-b6af-84be6809b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write csv files. Using fnusa as train\n",
    "df_train.to_csv('/scratch/mcesped/Datasets/Multiclass/df_train_curated.csv', sep=\",\", index_label='index')\n",
    "df_val.to_csv('/scratch/mcesped/Datasets/Multiclass/df_val_curated.csv', sep=\",\", index_label='index')\n",
    "# df_test.to_csv('/scratch/mcesped/Datasets/Noise_detection/df_test.csv', sep=\",\", index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03a4ea30-2ba1-4332-8950-7b65c660aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fnusa_no_pw.to_csv('/scratch/mcesped/Datasets/Multiclass/df_train_full.csv', sep=\",\", index_label='index')\n",
    "df_mayo_no_pw.to_csv('/scratch/mcesped/Datasets/Multiclass/df_val_full.csv', sep=\",\", index_label='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
